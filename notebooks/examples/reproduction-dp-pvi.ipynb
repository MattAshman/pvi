{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../..\"))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from pvi.models.logistic_regression import LogisticRegressionModel\n",
    "from pvi.clients.synchronous_client import SynchronousClient\n",
    "from pvi.servers.sequential_server import SequentialServer\n",
    "\n",
    "from pvi.distributions.exponential_family_distributions import MeanFieldGaussianDistribution\n",
    "from pvi.distributions.exponential_family_factors import MeanFieldGaussianFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-xerox",
   "metadata": {},
   "source": [
    "## Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../../data/preprocess_data.py --dir=./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-punishment",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_split(n_splits, n):\n",
    "\n",
    "    # Load inputs and outputs\n",
    "    x = np.load('./data/adult/x.npy')\n",
    "    y = np.load('./data/adult/y.npy')[:, 0]\n",
    "    \n",
    "    # Kfold splitter from sklearn\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=False)\n",
    "    \n",
    "    # Split data to 10 splits\n",
    "    splits = list(kfold.split(x))\n",
    "    \n",
    "    x_train = x[splits[n][0]]\n",
    "    x_valid = x[splits[n][1]]\n",
    "    \n",
    "    # Split data to 10 splits\n",
    "    splits = list(kfold.split(y))\n",
    "    \n",
    "    y_train = y[splits[n][0]]\n",
    "    y_valid = y[splits[n][1]]\n",
    "        \n",
    "    return x_train, x_valid, y_train,  y_valid\n",
    "\n",
    "\n",
    "def generate_clients_data(x, y, M, client_size_factor, class_balance_factor, dataset_seed):\n",
    "        # this function ought to return a list of (x, y) tuples.\n",
    "        # you need to set the seed in the main experiment file to ensure that this function becomes deterministic\n",
    "\n",
    "        random_state = np.random.get_state()\n",
    "\n",
    "        if dataset_seed is not None:\n",
    "            np.random.seed(dataset_seed)\n",
    "\n",
    "        if M == 1:\n",
    "            client_data = [{\"x\": x, \"y\": y}]\n",
    "            N_is = [x.shape[0]]\n",
    "            props_positive = [np.mean(y > 0)]\n",
    "\n",
    "            return client_data, N_is, props_positive, M\n",
    "\n",
    "        if M % 2 != 0: raise ValueError('Num clients should be even for nice maths')\n",
    "\n",
    "        N = x.shape[0]\n",
    "        small_client_size = int(np.floor((1 - client_size_factor) * N/M))\n",
    "        big_client_size = int(np.floor((1 + client_size_factor) * N/M))\n",
    "\n",
    "        class_balance = np.mean(y == 0)\n",
    "\n",
    "        small_client_class_balance = class_balance + (1 - class_balance) * class_balance_factor\n",
    "        small_client_negative_class_size = int(np.floor(small_client_size * small_client_class_balance))\n",
    "        small_client_positive_class_size = int(small_client_size - small_client_negative_class_size)\n",
    "\n",
    "        if small_client_negative_class_size < 0: raise ValueError('small_client_negative_class_size is negative, invalid settings.')\n",
    "        if small_client_positive_class_size < 0: raise ValueError('small_client_positive_class_size is negative, invalid settings.')\n",
    "\n",
    "\n",
    "        if small_client_negative_class_size * M/2 > class_balance * N:\n",
    "            raise ValueError(f'Not enough negative class instances to fill the small clients. Client size factor:{client_size_factor}, class balance factor:{class_balance_factor}')\n",
    "\n",
    "        if small_client_positive_class_size * M/2 > (1-class_balance) * N:\n",
    "            raise ValueError(f'Not enough positive class instances to fill the small clients. Client size factor:{client_size_factor}, class balance factor:{class_balance_factor}')\n",
    "\n",
    "\n",
    "        pos_inds = np.where(y > 0)\n",
    "        zero_inds = np.where(y == 0)\n",
    "        \n",
    "        assert (len(pos_inds[0]) + len(zero_inds[0])) == len(y), \"Some indeces missed.\"\n",
    "\n",
    "        y_pos = y[pos_inds]\n",
    "        y_neg = y[zero_inds]\n",
    "\n",
    "        x_pos = x[pos_inds]\n",
    "        x_neg = x[zero_inds]\n",
    "\n",
    "        client_data = []\n",
    "\n",
    "        # Populate small classes.\n",
    "        for i in range(int(M/2)):\n",
    "            client_x_pos = x_pos[:small_client_positive_class_size]\n",
    "            x_pos = x_pos[small_client_positive_class_size:]\n",
    "            client_y_pos = y_pos[:small_client_positive_class_size]\n",
    "            y_pos = y_pos[small_client_positive_class_size:]\n",
    "\n",
    "            client_x_neg = x_neg[:small_client_negative_class_size]\n",
    "            x_neg = x_neg[small_client_negative_class_size:]\n",
    "            client_y_neg = y_neg[:small_client_negative_class_size]\n",
    "            y_neg = y_neg[small_client_negative_class_size:]\n",
    "\n",
    "            client_x = np.concatenate([client_x_pos, client_x_neg])\n",
    "            client_y = np.concatenate([client_y_pos, client_y_neg])\n",
    "\n",
    "            shuffle_inds = np.random.permutation(client_x.shape[0])\n",
    "\n",
    "            client_x = client_x[shuffle_inds, :]\n",
    "            client_y = client_y[shuffle_inds]\n",
    "\n",
    "            client_data.append({'x': client_x, 'y': client_y})\n",
    "\n",
    "        # Recombine remaining data and shuffle.\n",
    "\n",
    "        x = np.concatenate([x_pos, x_neg])\n",
    "        y = np.concatenate([y_pos, y_neg])\n",
    "        shuffle_inds = np.random.permutation(x.shape[0])\n",
    "\n",
    "        x = x[shuffle_inds]\n",
    "        y = y[shuffle_inds]\n",
    "\n",
    "        # Distribute among large clients.\n",
    "        for i in range(int(M/2)):\n",
    "            client_x = x[:big_client_size]\n",
    "            client_y = y[:big_client_size]\n",
    "\n",
    "            x = x[big_client_size:]\n",
    "            y = y[big_client_size:]\n",
    "\n",
    "            client_data.append({'x': client_x, 'y': client_y})\n",
    "\n",
    "        N_is = [data['x'].shape[0] for data in client_data]\n",
    "        props_positive = [np.mean(data['y'] > 0) for data in client_data]\n",
    "\n",
    "        np.random.set_state(random_state)\n",
    "\n",
    "        return client_data, N_is, props_positive, M\n",
    "    \n",
    "    \n",
    "def acc_and_ll(server, x, y):\n",
    "    \n",
    "    pred_probs = server.model_predict(x)\n",
    "    pred_probs = pred_probs.mean.detach().numpy()\n",
    "    valid_acc = np.mean((pred_probs > 0.5) == y.numpy())\n",
    "    \n",
    "    probs = torch.clip(torch.tensor(pred_probs), 0., 1.)\n",
    "    valid_loglik = torch.distributions.Bernoulli(probs=probs).log_prob(y)\n",
    "    valid_loglik = valid_loglik.mean().numpy()\n",
    "    \n",
    "    return valid_acc, valid_loglik\n",
    "\n",
    "\n",
    "\n",
    "def standard_client_split(seed, num_clients, client_size_factor, class_balance_factor):\n",
    "\n",
    "    # Get data split\n",
    "    n_splits = 5\n",
    "    n = 4\n",
    "    full_data_split = get_nth_split(n_splits, n)\n",
    "    x_train, x_valid, y_train, y_valid = full_data_split\n",
    "\n",
    "    # Parameters for client data split\n",
    "    dataset_seed = seed\n",
    "\n",
    "    # Prepare training data held by each client\n",
    "    client_data, N, prop_positive, _ = generate_clients_data(x=x_train,\n",
    "                                                             y=y_train,\n",
    "                                                             M=num_clients,\n",
    "                                                             client_size_factor=client_size_factor,\n",
    "                                                             class_balance_factor=class_balance_factor,\n",
    "                                                             dataset_seed=dataset_seed)\n",
    "\n",
    "    # Validation set, to predict on using global model\n",
    "    valid_set = {'x' : torch.tensor(x_valid).float(),\n",
    "                 'y' : torch.tensor(y_valid).float()}\n",
    "    \n",
    "    return client_data, valid_set, N, prop_positive, full_data_split\n",
    "\n",
    "\n",
    "def set_up_clients(model, client_data, init_nat_params):\n",
    "\n",
    "    clients = []\n",
    "\n",
    "    # Create clients\n",
    "    for _client_data in client_data:\n",
    "\n",
    "        # Data of ith client\n",
    "        data = {k : torch.tensor(v).float() for k, v in _client_data.items()}\n",
    "\n",
    "        # Approximating likelihood term of ith client\n",
    "        t = MeanFieldGaussianFactor(nat_params=init_nat_params)\n",
    "\n",
    "        # Create client and store\n",
    "        client = SynchronousClient(data=data, model=model, t=t)\n",
    "        clients.append(client)\n",
    "        \n",
    "    return clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-journey",
   "metadata": {},
   "source": [
    "# Experiment setup A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 0\n",
    "# client_size_factor = 0.\n",
    "# class_balance_factor = 0.\n",
    "# max_iterations = 10\n",
    "# num_clients = 10\n",
    "\n",
    "# client_data, valid_set, N, prop_positive, full_data_split = standard_client_split(seed, num_clients, client_size_factor, class_balance_factor)\n",
    "# x_train, x_valid, y_train, y_valid = full_data_split\n",
    "\n",
    "# print(f'Proporition of positive examples in each client: {np.array(prop_positive).round(2)}')\n",
    "# print(f'Total number of examples in each client        : {N}')\n",
    "\n",
    "# experiment_params = standard_experiment_params()\n",
    "# D, hyperparameters, prior_std_params, init_nat_params = experiment_params\n",
    "\n",
    "# # Common likelihood model shared by all clients\n",
    "# model = LogisticRegressionModel(hyperparameters=hyperparameters)\n",
    "\n",
    "# # Initialise clients, q and server\n",
    "# clients = set_up_clients(model, client_data, init_nat_params)\n",
    "# q = MeanFieldGaussianDistribution(std_params=prior_std_params,\n",
    "#                                   is_trainable=False)\n",
    "# server = SequentialServer(model=model,\n",
    "#                           q=q,\n",
    "#                           clients=clients,\n",
    "#                           hyperparameters={\"max_iterations\" : max_iterations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_valid_every = 1\n",
    "\n",
    "# while not server.should_stop():\n",
    "    \n",
    "#     server.tick()\n",
    "    \n",
    "#     train_acc, train_loglik = acc_and_ll(server, torch.tensor(x_train).float(), torch.tensor(y_train).float())\n",
    "#     valid_acc, valid_loglik = acc_and_ll(server, valid_set['x'], valid_set['y'])\n",
    "    \n",
    "#     print(f'Train: accuracy {train_acc:.3f}, mean-loglik {train_loglik:.3f}\\n'\n",
    "#           f'Valid: accuracy {valid_acc:.3f}, mean-loglik {valid_loglik:.3f}\\n')\n",
    "        \n",
    "        \n",
    "#     plt.figure(figsize=(2 * num_clients, 6))\n",
    "\n",
    "#     for i in range(num_clients):\n",
    "\n",
    "#         plt.subplot(3, num_clients, i + 1)\n",
    "#         elbo = server.get_compiled_log()[f'client_{i}']['training_curves'][server.iterations-1]['elbo']\n",
    "#         plt.plot(elbo)\n",
    "        \n",
    "#         plt.subplot(3, num_clients, num_clients + i + 1)\n",
    "#         kl = server.get_compiled_log()[f'client_{i}']['training_curves'][server.iterations-1]['kl']\n",
    "#         plt.plot(- np.array(kl))\n",
    "        \n",
    "#         plt.subplot(3, num_clients, 2 * num_clients + i + 1)\n",
    "#         ll = server.get_compiled_log()[f'client_{i}']['training_curves'][server.iterations-1]['ll']\n",
    "#         plt.plot(ll)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-album",
   "metadata": {},
   "source": [
    "# Experiment setup B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "client_size_factor = 0.9\n",
    "class_balance_factor = 0.95\n",
    "max_iterations = 20\n",
    "num_clients = 10\n",
    "\n",
    "client_data, valid_set, N, prop_positive, full_data_split = standard_client_split(seed, num_clients, client_size_factor, class_balance_factor)\n",
    "x_train, x_valid, y_train, y_valid = full_data_split\n",
    "\n",
    "print(f'Proporition of positive examples in each client: {np.array(prop_positive).round(2)}')\n",
    "print(f'Total number of examples in each client        : {N}')\n",
    "\n",
    "experiment_params = standard_experiment_params()\n",
    "D, hyperparameters, prior_std_params, init_nat_params = experiment_params\n",
    "\n",
    "# Common likelihood model shared by all clients\n",
    "model = LogisticRegressionModel(hyperparameters=hyperparameters)\n",
    "\n",
    "# Initialise clients, q and server\n",
    "clients = set_up_clients(model, client_data, init_nat_params)\n",
    "q = MeanFieldGaussianDistribution(std_params=prior_std_params,\n",
    "                                  is_trainable=False)\n",
    "server = SequentialServer(model=model,\n",
    "                          q=q,\n",
    "                          clients=clients,\n",
    "                          hyperparameters={\"max_iterations\" : max_iterations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_valid_every = 1\n",
    "\n",
    "while not server.should_stop():\n",
    "    \n",
    "    server.tick()\n",
    "    \n",
    "    train_acc, train_loglik = acc_and_ll(server, torch.tensor(x_train).float(), torch.tensor(y_train).float())\n",
    "    valid_acc, valid_loglik = acc_and_ll(server, valid_set['x'], valid_set['y'])\n",
    "    \n",
    "    print(f'Train: accuracy {train_acc:.3f}, mean-loglik {train_loglik:.3f}\\n'\n",
    "          f'Valid: accuracy {valid_acc:.3f}, mean-loglik {valid_loglik:.3f}\\n')\n",
    "        \n",
    "        \n",
    "    plt.figure(figsize=(2 * num_clients, 6))\n",
    "\n",
    "    for i in range(num_clients):\n",
    "\n",
    "        plt.subplot(3, num_clients, i + 1)\n",
    "        elbo = server.get_compiled_log()[f'client_{i}']['training_curves'][server.iterations-1]['elbo']\n",
    "        plt.plot(elbo)\n",
    "        \n",
    "        plt.subplot(3, num_clients, num_clients + i + 1)\n",
    "        kl = server.get_compiled_log()[f'client_{i}']['training_curves'][server.iterations-1]['kl']\n",
    "        plt.plot(- np.array(kl))\n",
    "        \n",
    "        plt.subplot(3, num_clients, 2 * num_clients + i + 1)\n",
    "        ll = server.get_compiled_log()[f'client_{i}']['training_curves'][server.iterations-1]['ll']\n",
    "        plt.plot(ll)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-notion",
   "metadata": {},
   "source": [
    "# Test setup C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "client_size_factor = 0.7\n",
    "class_balance_factor = -3.\n",
    "max_iterations = 50\n",
    "num_clients = 10\n",
    "\n",
    "client_data, valid_set, N, prop_positive, full_data_split = standard_client_split(seed,\n",
    "                                                                                  num_clients,\n",
    "                                                                                  client_size_factor,\n",
    "                                                                                  class_balance_factor)\n",
    "x_train, x_valid, y_train, y_valid = full_data_split\n",
    "\n",
    "print(f'Proporition of positive examples in each client: {np.array(prop_positive).round(2)}')\n",
    "print(f'Total number of examples in each client        : {N}')\n",
    "\n",
    "experiment_params = standard_experiment_params()\n",
    "D, hyperparameters, prior_std_params, init_nat_params = experiment_params\n",
    "\n",
    "# Common likelihood model shared by all clients\n",
    "model = LogisticRegressionModel(hyperparameters=hyperparameters)\n",
    "\n",
    "# Initialise clients, q and server\n",
    "clients = set_up_clients(model, client_data, init_nat_params)\n",
    "q = MeanFieldGaussianDistribution(std_params=prior_std_params,\n",
    "                                  is_trainable=False)\n",
    "server = SequentialServer(model=model,\n",
    "                          q=q,\n",
    "                          clients=clients,\n",
    "                          hyperparameters={\"max_iterations\" : max_iterations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_valid_every = 1\n",
    "\n",
    "while not server.should_stop():\n",
    "    \n",
    "    server.tick()\n",
    "    \n",
    "    train_acc, train_loglik = acc_and_ll(server, torch.tensor(x_train).float(), torch.tensor(y_train).float())\n",
    "    valid_acc, valid_loglik = acc_and_ll(server, valid_set['x'], valid_set['y'])\n",
    "    \n",
    "    print(f'Train: accuracy {train_acc:.3f}, mean-loglik {train_loglik:.3f}\\n'\n",
    "          f'Valid: accuracy {valid_acc:.3f}, mean-loglik {valid_loglik:.3f}\\n')\n",
    "        \n",
    "        \n",
    "    plt.figure(figsize=(2 * num_clients, 6))\n",
    "\n",
    "    for i in range(num_clients):\n",
    "\n",
    "        plt.subplot(3, num_clients, i + 1)\n",
    "        elbo = server.get_compiled_log()[f'client_{i}']['training_curves'][server.iterations-1]['elbo']\n",
    "        plt.plot(elbo)\n",
    "        \n",
    "        plt.subplot(3, num_clients, num_clients + i + 1)\n",
    "        kl = server.get_compiled_log()[f'client_{i}']['training_curves'][server.iterations-1]['kl']\n",
    "        plt.plot(- np.array(kl))\n",
    "        \n",
    "        plt.subplot(3, num_clients, 2 * num_clients + i + 1)\n",
    "        ll = server.get_compiled_log()[f'client_{i}']['training_curves'][server.iterations-1]['ll']\n",
    "        plt.plot(ll)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-legend",
   "metadata": {},
   "source": [
    "## Sanity check: Global VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "client_size_factor = 0.\n",
    "class_balance_factor = 0.\n",
    "max_iterations = 10\n",
    "num_clients = 1\n",
    "\n",
    "client_data, valid_set, N, prop_positive, full_data_split = standard_client_split(seed, num_clients, client_size_factor, class_balance_factor)\n",
    "x_train, x_valid, y_train, y_valid = full_data_split\n",
    "\n",
    "print(f'Proporition of positive examples in each client: {np.array(prop_positive).round(2)}')\n",
    "print(f'Total number of examples in each client        : {N}')\n",
    "\n",
    "experiment_params = standard_experiment_params()\n",
    "D, hyperparameters, prior_std_params, init_nat_params = experiment_params\n",
    "\n",
    "# Common likelihood model shared by all clients\n",
    "model = LogisticRegressionModel(hyperparameters=hyperparameters)\n",
    "\n",
    "# Initialise clients, q and server\n",
    "clients = set_up_clients(model, client_data, init_nat_params)\n",
    "q = MeanFieldGaussianDistribution(std_params=prior_std_params,\n",
    "                                  is_trainable=False)\n",
    "server = SequentialServer(model=model,\n",
    "                          q=q,\n",
    "                          clients=clients,\n",
    "                          hyperparameters={\"max_iterations\" : max_iterations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_valid_every = 1\n",
    "\n",
    "while not server.should_stop():\n",
    "    \n",
    "    server.tick()\n",
    "    \n",
    "    train_acc, train_loglik = acc_and_ll(server, torch.tensor(x_train).float(), torch.tensor(y_train).float())\n",
    "    valid_acc, valid_loglik = acc_and_ll(server, valid_set['x'], valid_set['y'])\n",
    "     \n",
    "    print(f'Train: accuracy {train_acc:.3f}, mean-loglik {train_loglik:.3f}\\n'\n",
    "          f'Valid: accuracy {valid_acc:.3f}, mean-loglik {valid_loglik:.3f}\\n')\n",
    "        \n",
    "        \n",
    "    plt.figure(figsize=(2 * num_clients, 6))\n",
    "\n",
    "    for i in range(num_clients):\n",
    "\n",
    "        plt.subplot(3, num_clients, i + 1)\n",
    "        elbo = server.get_compiled_log()[f'client_{i}']['training_curves'][server.iterations-1]['elbo']\n",
    "        plt.plot(elbo)\n",
    "        \n",
    "        plt.subplot(3, num_clients, num_clients + i + 1)\n",
    "        kl = server.get_compiled_log()[f'client_{i}']['training_curves'][server.iterations-1]['kl']\n",
    "        plt.plot(- np.array(kl))\n",
    "        \n",
    "        plt.subplot(3, num_clients, 2 * num_clients + i + 1)\n",
    "        ll = server.get_compiled_log()[f'client_{i}']['training_curves'][server.iterations-1]['ll']\n",
    "        plt.plot(ll)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-cancer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvi",
   "language": "python",
   "name": "pvi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
