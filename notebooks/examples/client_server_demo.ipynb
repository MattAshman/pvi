{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vocal-inspector",
   "metadata": {},
   "source": [
    "# PVI demo on the adult dataset\n",
    "Using the codebase splits as in <https://github.com/MrinankSharma/DP-PVI>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pvi.models.logistic_regression import LogisticRegressionModel\n",
    "from pvi.utils.gaussian import mvstandard2natural, mvnatural2standard\n",
    "from pvi.clients.synchronous_client import SynchronousClient\n",
    "from pvi.servers.sequential_server import SequentialServer\n",
    "from pvi.distributions.exponential_family_distributions import \\\n",
    "    MultivariateGaussianDistribution, MeanFieldGaussianDistribution\n",
    "from pvi.distributions.exponential_family_factors import \\\n",
    "    MultivariateGaussianFactor, MeanFieldGaussianFactor\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.auto as tqdm\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "%matplotlib inline\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-tracy",
   "metadata": {},
   "source": [
    "### Set up data and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-baseball",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_filename(name, scaled, ordinal_cat_encoding, data_base_dir):\n",
    "    filename_x = \"x\"\n",
    "    ret_y = data_base_dir + name + \"/y.csv\"\n",
    "    if scaled:\n",
    "        filename_x = filename_x + \"_scaled\"\n",
    "\n",
    "    if ordinal_cat_encoding:\n",
    "        filename_x = filename_x + \"_ordinal\"\n",
    "\n",
    "    filename_x = filename_x + \".csv\"\n",
    "    ret = os.path.join(data_base_dir, name, filename_x)\n",
    "    ret_y = os.path.join(data_base_dir, name, \"y.csv\")\n",
    "    \n",
    "    return ret, ret_y\n",
    "\n",
    "def load_data(name, scaled, ordinal_cat_encoding, train_proportion, data_base_dir):\n",
    "    x_loc, y_loc = generate_filename(name, scaled, ordinal_cat_encoding, data_base_dir)\n",
    "    x = np.loadtxt(x_loc, delimiter=\",\")\n",
    "    y = np.loadtxt(y_loc, delimiter=\",\")\n",
    "    \n",
    "    # Replace -1's with 0's.\n",
    "    y[y == -1] = 0\n",
    "    \n",
    "    N = x.shape[0]\n",
    "    N_train = int(np.ceil(train_proportion * N))\n",
    "    \n",
    "    x_train = x[0:N_train]\n",
    "    y_train = y[0:N_train]\n",
    "    x_test = x[N_train:]\n",
    "    y_test = y[N_train:]\n",
    "\n",
    "    training_set = {\n",
    "        \"x\": x_train,\n",
    "        \"y\": y_train,\n",
    "    }\n",
    "\n",
    "    test_set = {\n",
    "        \"x\": x_test,\n",
    "        \"y\": y_test\n",
    "    }\n",
    "\n",
    "    D = x_test.shape[1]\n",
    "\n",
    "    return training_set, test_set, D\n",
    "\n",
    "def generate_clients_data(x, y, M, client_size_factor, class_balance_factor, dataset_seed):\n",
    "        # this function ought to return a list of (x, y) tuples.\n",
    "        # you need to set the seed in the main experiment file to ensure that this function becomes deterministic\n",
    "\n",
    "        random_state = np.random.get_state()\n",
    "\n",
    "        if dataset_seed is not None:\n",
    "            np.random.seed(dataset_seed)\n",
    "\n",
    "        if M == 1:\n",
    "            client_data = [{\"x\": x, \"y\": y}]\n",
    "            N_is = [x.shape[0]]\n",
    "            props_positive = [np.mean(y > 0)]\n",
    "\n",
    "            return client_data, N_is, props_positive, M\n",
    "\n",
    "        if M % 2 != 0: raise ValueError('Num clients should be even for nice maths')\n",
    "\n",
    "        N = x.shape[0]\n",
    "        small_client_size = int(np.floor((1 - client_size_factor) * N/M))\n",
    "        big_client_size = int(np.floor((1 + client_size_factor) * N/M))\n",
    "\n",
    "        class_balance = np.mean(y == 0)\n",
    "\n",
    "        small_client_class_balance = class_balance + (1 - class_balance) * class_balance_factor\n",
    "        small_client_negative_class_size = int(np.floor(small_client_size * small_client_class_balance))\n",
    "        small_client_positive_class_size = int(small_client_size - small_client_negative_class_size)\n",
    "\n",
    "        if small_client_negative_class_size < 0: raise ValueError('small_client_negative_class_size is negative, invalid settings.')\n",
    "        if small_client_positive_class_size < 0: raise ValueError('small_client_positive_class_size is negative, invalid settings.')\n",
    "\n",
    "\n",
    "        if small_client_negative_class_size * M/2 > class_balance * N:\n",
    "            raise ValueError(f'Not enough negative class instances to fill the small clients. Client size factor:{client_size_factor}, class balance factor:{class_balance_factor}')\n",
    "\n",
    "        if small_client_positive_class_size * M/2 > (1-class_balance) * N:\n",
    "            raise ValueError(f'Not enough positive class instances to fill the small clients. Client size factor:{client_size_factor}, class balance factor:{class_balance_factor}')\n",
    "\n",
    "\n",
    "        pos_inds = np.where(y > 0)\n",
    "        zero_inds = np.where(y == 0)\n",
    "        \n",
    "        assert (len(pos_inds[0]) + len(zero_inds[0])) == len(y), \"Some indeces missed.\"\n",
    "        \n",
    "        print(f'x shape {x.shape}')\n",
    "        print(f'positive indices {pos_inds}')\n",
    "        print(f'zero indices {zero_inds}')\n",
    "\n",
    "        y_pos = y[pos_inds]\n",
    "        y_neg = y[zero_inds]\n",
    "\n",
    "        x_pos = x[pos_inds]\n",
    "        x_neg = x[zero_inds]\n",
    "\n",
    "        client_data = []\n",
    "\n",
    "        # Populate small classes.\n",
    "        for i in range(int(M/2)):\n",
    "            client_x_pos = x_pos[:small_client_positive_class_size]\n",
    "            x_pos = x_pos[small_client_positive_class_size:]\n",
    "            client_y_pos = y_pos[:small_client_positive_class_size]\n",
    "            y_pos = y_pos[small_client_positive_class_size:]\n",
    "\n",
    "            client_x_neg = x_neg[:small_client_negative_class_size]\n",
    "            x_neg = x_neg[small_client_negative_class_size:]\n",
    "            client_y_neg = y_neg[:small_client_negative_class_size]\n",
    "            y_neg = y_neg[small_client_negative_class_size:]\n",
    "\n",
    "            client_x = np.concatenate([client_x_pos, client_x_neg])\n",
    "            client_y = np.concatenate([client_y_pos, client_y_neg])\n",
    "\n",
    "            shuffle_inds = np.random.permutation(client_x.shape[0])\n",
    "\n",
    "            client_x = client_x[shuffle_inds, :]\n",
    "            client_y = client_y[shuffle_inds]\n",
    "\n",
    "            client_data.append({'x': client_x, 'y': client_y})\n",
    "\n",
    "        # Recombine remaining data and shuffle.\n",
    "\n",
    "        x = np.concatenate([x_pos, x_neg])\n",
    "        y = np.concatenate([y_pos, y_neg])\n",
    "        shuffle_inds = np.random.permutation(x.shape[0])\n",
    "\n",
    "        x = x[shuffle_inds]\n",
    "        y = y[shuffle_inds]\n",
    "\n",
    "        # Distribute among large clients.\n",
    "        for i in range(int(M/2)):\n",
    "            client_x = x[:big_client_size]\n",
    "            client_y = y[:big_client_size]\n",
    "\n",
    "            x = x[big_client_size:]\n",
    "            y = y[big_client_size:]\n",
    "\n",
    "            client_data.append({'x': client_x, 'y': client_y})\n",
    "\n",
    "        N_is = [data['x'].shape[0] for data in client_data]\n",
    "        props_positive = [np.mean(data['y'] > 0) for data in client_data]\n",
    "\n",
    "        np.random.set_state(random_state)\n",
    "\n",
    "        print(f'N_is {N_is}')\n",
    "        print(f'Props positive: {props_positive}')\n",
    "\n",
    "        return client_data, N_is, props_positive, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"adult\"\n",
    "scaled = True\n",
    "ordinal_cat_encoding = True\n",
    "train_proportion = 0.25\n",
    "data_base_dir = \"/Users/matt/projects/pvi/datasets\"\n",
    "\n",
    "training_set, test_set, D = load_data(\n",
    "    name, scaled, ordinal_cat_encoding, train_proportion, data_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10\n",
    "\n",
    "clients_data, nis, prop_positive, M = generate_clients_data(\n",
    "    training_set[\"x\"], \n",
    "    training_set[\"y\"],\n",
    "    M=M,\n",
    "    client_size_factor=0,\n",
    "    class_balance_factor=0,\n",
    "    dataset_seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-decimal",
   "metadata": {},
   "source": [
    "### Set up clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "\n",
    "# Shared across all clients.\n",
    "hyperparameters = {\n",
    "    \"D\": D,\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"optimiser_params\": {\"lr\": 1e-2},\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 100,\n",
    "    \"num_elbo_samples\": 1,\n",
    "    \"num_predictive_samples\": 10\n",
    "}\n",
    "\n",
    "prior_std_params = {\n",
    "    \"loc\": torch.zeros(hyperparameters[\"D\"] + 1),\n",
    "    \"scale\": torch.ones(hyperparameters[\"D\"] + 1),\n",
    "}\n",
    "\n",
    "init_nat_params = {\n",
    "    \"np1\": torch.zeros(hyperparameters[\"D\"] + 1),\n",
    "    \"np2\": torch.zeros(hyperparameters[\"D\"] + 1),\n",
    "}\n",
    "\n",
    "# Construct clients.\n",
    "for i in range(M):\n",
    "    model_i = LogisticRegressionModel(hyperparameters=hyperparameters)\n",
    "    data_i = clients_data[i]\n",
    "    t_i = MeanFieldGaussianFactor(nat_params=init_nat_params)\n",
    "    \n",
    "    # Convert to torch.tensor.\n",
    "    for k, v in data_i.items():\n",
    "        data_i[k] = torch.tensor(v)\n",
    "    \n",
    "    clients.append(SynchronousClient(data=data_i, model=model_i, t=t_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct server.\n",
    "model = LogisticRegressionModel(hyperparameters=hyperparameters)\n",
    "q = MeanFieldGaussianDistribution(std_params=prior_std_params, is_trainable=False)\n",
    "server = SequentialServer(model=model, q=q, clients=clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-reynolds",
   "metadata": {},
   "source": [
    "### Run PVI!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "while not server.should_stop():\n",
    "    server.tick()\n",
    "\n",
    "    # Obtain predictions.\n",
    "    pp = server.model_predict(torch.tensor(test_set[\"x\"]))\n",
    "    preds = pp.mean.detach().numpy()\n",
    "    test_acc = np.sum(\n",
    "        np.abs(2 * (preds > 0.5) - 1 + test_set[\"y\"]) > 0) / np.size(test_set[\"y\"])\n",
    "    \n",
    "    print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(training_array, ax=None):\n",
    "    x_vals = np.arange(1, len(training_array)+1)\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    ax.grid(b=True)\n",
    "    ax.plot(x_vals, training_array)\n",
    "    ax.set_xlabel('Step')\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = server.get_compiled_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = len(clients)\n",
    "ncols = 8\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(ncols*3, nrows*5), nrows=nrows, ncols=ncols, sharey=\"row\")\n",
    "\n",
    "for i, client in enumerate(server.clients):\n",
    "    for j in range(ncols):\n",
    "        ax = axes[i, j]\n",
    "        plot_training(logs[f\"client_{i}\"][\"training_curves\"][j][\"elbo\"], ax)\n",
    "        \n",
    "    axes[i, 0].set_ylabel(\"Client {}\".format(i))\n",
    "    \n",
    "for j in range(ncols):\n",
    "    axes[0, j].set_title(\"Iteration {}\".format(j))\n",
    "        \n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-evaluation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
