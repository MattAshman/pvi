{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "breeding-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pvi\n",
    "from pvi.models import ClassificationBNNLocalRepam\n",
    "from pvi.clients import Client\n",
    "from pvi.servers import SequentialServer\n",
    "from pvi.distributions import MeanFieldGaussianDistribution, MeanFieldGaussianFactor\n",
    "from pvi.utils.training_utils import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435545ad-fcfd-45d0-a1cd-18239fc50e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/Users/matt/projects/datasets\")\n",
    "cache_dir = Path(\"/Users/matt/projects/pvi/rough/experiments/femnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a3148a-a47d-48e5-b7c6-ad151426b14d",
   "metadata": {},
   "source": [
    "## Define various functions for splitting data and recording performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f50d7529-98c4-4e24-b2ed-da080394cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting functions.\n",
    "def homogeneous_split(data, num_clients=100, seed=42):\n",
    "    # Set numpy's random seed.\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    perm = np.random.permutation(len(data[\"x\"]))\n",
    "    client_data = []\n",
    "    for i in range(num_clients):\n",
    "        client_idx = perm[i::num_clients]\n",
    "        client_data.append({\"x\": data[\"x\"][client_idx], \"y\": data[\"y\"][client_idx]})\n",
    "    \n",
    "    return client_data\n",
    "\n",
    "\n",
    "# Performance metric function.\n",
    "def performance_metrics(client, data, batch_size=512):\n",
    "    dataset = torch.utils.data.TensorDataset(data[\"x\"], data[\"y\"])\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=512, shuffle=False)\n",
    "    \n",
    "    device = client.config[\"device\"]\n",
    "    \n",
    "    if device == \"cuda\":\n",
    "        loader.pin_memory = True\n",
    "        \n",
    "    preds, mlls = [], []\n",
    "    for (x_batch, y_batch) in loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        pp = client.model_predict(x_batch)\n",
    "        preds.append(pp.component_distribution.probs.mean(1).cpu())\n",
    "        mlls.append(pp.log_prob(y_batch).cpu())\n",
    "        \n",
    "    mll = torch.cat(mlls).mean()\n",
    "    preds = torch.cat(preds)\n",
    "    acc = sum(torch.argmax(preds, dim=-1) == loader.dataset.tensors[1]) / len(\n",
    "        loader.dataset.tensors[1]\n",
    "    )\n",
    "    \n",
    "    return {\"mll\": mll, \"acc\": acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99665737-174b-4c35-80f6-1587d6218f90",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eba7ac03-a22b-4427-b61d-e6a116b21826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /Users/matt/projects/datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8431af2a7a7f4f8b9a2967090418fbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/matt/projects/datasets/MNIST/raw/train-images-idx3-ubyte.gz to /Users/matt/projects/datasets/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /Users/matt/projects/datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e8865a9b5246a0a99fbabbbe1e8896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/matt/projects/datasets/MNIST/raw/train-labels-idx1-ubyte.gz to /Users/matt/projects/datasets/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /Users/matt/projects/datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f99777be5f645c5956eb018d5a18978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/matt/projects/datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to /Users/matt/projects/datasets/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /Users/matt/projects/datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23cdac80f94840d09eb34b1fdf303c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/matt/projects/datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to /Users/matt/projects/datasets/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matt/opt/miniconda3/envs/pvi/lib/python3.9/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /tmp/pip-req-build-x1rp5px8/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([transforms.ToTensor()])\n",
    "transform_test = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_set = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform_train)\n",
    "test_set = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_data = {\n",
    "    \"x\": ((train_set.data - 0) / 255).reshape(-1, 28 * 28),\n",
    "    \"y\": train_set.targets,\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    \"x\": ((test_set.data - 0) / 255).reshape(-1, 28 * 28),\n",
    "    \"y\": test_set.targets,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c5e7f50-4b69-4cf7-baea-4fd18076d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get client splits.\n",
    "client_data = homogeneous_split(train_data, 10, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494906de-3e8e-4c61-bfa6-100ba7501926",
   "metadata": {},
   "source": [
    "## Define configuration for server and clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d7682e6-5891-40f6-940d-171616bae48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"input_dim\": 784,\n",
    "    \"latent_dim\": 200,\n",
    "    \"output_dim\": 10,\n",
    "    \"num_layers\": 1,\n",
    "    \"num_predictive_samples\": 100,\n",
    "    \"prior_var\": 1.0,\n",
    "}\n",
    "\n",
    "client_config = {\n",
    "    \"damping_factor\": 1.0,\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"optimiser_params\": {\"lr\": 2e-3},\n",
    "    \"sigma_optimiser_params\": {\"lr\": 2e-3},\n",
    "    \"early_stopping\": EarlyStopping(5, score_name=\"elbo\", stash_model=True),\n",
    "    \"performance_metrics\": performance_metrics,\n",
    "    \"batch_size\": 512,\n",
    "    \"epochs\": 2000,\n",
    "    \"print_epochs\": np.inf,\n",
    "    \"num_elbo_samples\": 10,\n",
    "    \"valid_factors\": False,\n",
    "    \"device\": \"cpu\",\n",
    "    \"init_var\": 1e-3,\n",
    "    \"verbose\": True,\n",
    "}\n",
    "\n",
    "server_config = {\n",
    "    **client_config,\n",
    "    \"max_iterations\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196ce95c-3c55-496d-922f-997bb5d049b2",
   "metadata": {},
   "source": [
    "## Set up model etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae71b9e9-5686-478d-9086-0a06a268a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = server_config[\"device\"]\n",
    "\n",
    "model = ClassificationBNNLocalRepam(config=model_config)\n",
    "\n",
    "# Initial parameters.\n",
    "init_q_std_params = {\n",
    "    \"loc\": torch.zeros(size=(model.num_parameters,)).to(device).uniform_(-0.1, 0.1),\n",
    "    \"scale\": torch.ones(size=(model.num_parameters,)).to(device) \n",
    "    * client_config[\"init_var\"] ** 0.5,\n",
    "}\n",
    "\n",
    "prior_std_params = {\n",
    "    \"loc\": torch.zeros(size=(model.num_parameters,)).to(device),\n",
    "    \"scale\": model_config[\"prior_var\"] ** 0.5 \n",
    "    * torch.ones(size=(model.num_parameters,)).to(device),\n",
    "}\n",
    "\n",
    "init_factor_nat_params = {\n",
    "    \"np1\": torch.zeros(model.num_parameters).to(device),\n",
    "    \"np2\": torch.zeros(model.num_parameters).to(device),\n",
    "}\n",
    "\n",
    "p = MeanFieldGaussianDistribution(\n",
    "    std_params=prior_std_params, is_trainable=False\n",
    ")\n",
    "init_q = MeanFieldGaussianDistribution(\n",
    "    std_params=init_q_std_params, is_trainable=False\n",
    ")\n",
    "\n",
    "clients = []\n",
    "for i in range(10):\n",
    "    data_i = client_data[i]\n",
    "    t_i = MeanFieldGaussianFactor(nat_params=init_factor_nat_params)\n",
    "    clients.append(\n",
    "        Client(\n",
    "            data=data_i,\n",
    "            model=model,\n",
    "            t=t_i,\n",
    "            config=client_config,\n",
    "            val_data=test_data\n",
    "        )\n",
    "    )\n",
    "    \n",
    "server = SequentialServer(model=model, p=p, clients=clients, config=server_config, init_q=init_q, data=train_data, val_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db69f6-b2ae-419a-b8f3-1efb8dc8bcda",
   "metadata": {},
   "source": [
    "## Run PVI!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc1f6b1f-6da0-460c-8a6b-032288230f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2756b9b2c04b90b0ebe55354997696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a55760b620e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Obtain performance metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/pvi/pvi/servers/base.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/pvi/pvi/servers/sequential_server.py\u001b[0m in \u001b[0;36m_tick\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 ):\n\u001b[1;32m     32\u001b[0m                     \u001b[0;31m# First iteration. Pass q_init(θ) to client.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/pvi/pvi/clients/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall\u001b[0m \u001b[0mcases\u001b[0m \u001b[0mit\u001b[0m \u001b[0mcalls\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_update\u001b[0m \u001b[0minternally\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_q\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/pvi/pvi/clients/base.py\u001b[0m in \u001b[0;36mupdate_q\u001b[0;34m(self, q, init_q, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;31m# Pass a trainable copy to optimise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_based_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_q\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/pvi/pvi/clients/base.py\u001b[0m in \u001b[0;36mgradient_based_update\u001b[0;34m(self, p, init_q, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;31m# Sample θ from q and compute p(y | θ, x) for each θ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 ll = self.model.expected_log_likelihood(\n\u001b[0m\u001b[1;32m    254\u001b[0m                     \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_elbo_samples\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 ).sum()\n",
      "\u001b[0;32m~/projects/pvi/pvi/models/bnn/bnn.py\u001b[0m in \u001b[0;36mexpected_log_likelihood\u001b[0;34m(self, data, q, num_samples)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_repam_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mqy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_dist_from_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/pvi/pvi/models/bnn/bnn.py\u001b[0m in \u001b[0;36mlocal_repam_forward\u001b[0;34m(self, x, q, num_samples)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;31m# (batch_size, dim_out).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mqh_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqw_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mqh_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqw_scale\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;31m# Use different random sample for each datapoint to reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while not server.should_stop():\n",
    "    server.tick()\n",
    "    \n",
    "    # Obtain performance metrics.\n",
    "    metrics = server.log[\"performance_metrics\"][-1]\n",
    "    print(\"Iterations: {}.\".format(i))\n",
    "    print(\"Time taken: {:.3f}.\".format(metrics[\"time\"]))\n",
    "    print(\n",
    "      \"Test mll: {:.3f}. Test acc: {:.3f}.\".format(\n",
    "          metrics[\"val_mll\"], metrics[\"val_acc\"]\n",
    "      )\n",
    "    )\n",
    "    print(\n",
    "      \"Train mll: {:.3f}. Train acc: {:.3f}.\\n\".format(\n",
    "          metrics[\"train_mll\"], metrics[\"train_acc\"]\n",
    "      )\n",
    "    )\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
