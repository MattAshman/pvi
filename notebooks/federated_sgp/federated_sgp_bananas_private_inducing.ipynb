{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ordinary-panama",
   "metadata": {},
   "source": [
    "# Federated SGP demo on banana dataset with private inducing points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pvi.models import SparseGaussianProcessClassification\n",
    "from pvi.distributions import MultivariateGaussianDistributionWithZ, MultivariateGaussianFactorWithZ\n",
    "from pvi.distributions import LogNormalDistribution, LogNormalFactor\n",
    "from pvi.distributions.hypers import HyperparameterDistribution, HyperparameterFactor\n",
    "from pvi.clients.federated_sgp import FederatedSGPClient\n",
    "from pvi.servers.federated_sgp import SequentialSGPServer, SynchronousSGPServer\n",
    "from pvi.utils.training_utils import EarlyStopping\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.auto as tqdm\n",
    "import gpytorch\n",
    "\n",
    "from torch import nn\n",
    "from pvi.models.sgp.kernels import RBFKernel\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-relation",
   "metadata": {},
   "source": [
    "### Set up data and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-sapphire",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(name, train_proportion, data_base_dir):\n",
    "    filename = os.path.join(data_base_dir, name, \"banana.csv\")\n",
    "    data = np.loadtxt(filename, delimiter=\",\", skiprows=1)\n",
    "    \n",
    "    x = data[:, :2]\n",
    "    y = data[:, -1]\n",
    "    \n",
    "    # Replace 1's with 0's and 2's with 1's.\n",
    "    y[y == 1] = 0\n",
    "    y[y == 2] = 1\n",
    "    \n",
    "    N = x.shape[0]\n",
    "    N_train = int(np.ceil(train_proportion * N))\n",
    "    \n",
    "    x_train = x[0:N_train]\n",
    "    y_train = y[0:N_train]\n",
    "    x_test = x[N_train:]\n",
    "    y_test = y[N_train:]\n",
    "\n",
    "    training_set = {\n",
    "        \"x\": x_train,\n",
    "        \"y\": y_train,\n",
    "    }\n",
    "\n",
    "    test_set = {\n",
    "        \"x\": x_test,\n",
    "        \"y\": y_test\n",
    "    }\n",
    "\n",
    "    D = x_test.shape[1]\n",
    "    \n",
    "    del data\n",
    "\n",
    "    return training_set, test_set, D\n",
    "\n",
    "def generate_clients_data(x, y, M, dataset_seed):\n",
    "        random_state = np.random.get_state()\n",
    "\n",
    "        if dataset_seed is not None:\n",
    "            np.random.seed(dataset_seed)\n",
    "\n",
    "        if M == 1:\n",
    "            client_data = [{\"x\": x, \"y\": y}]\n",
    "            N_is = [x.shape[0]]\n",
    "            props_positive = [np.mean(y > 0)]\n",
    "\n",
    "            return client_data, N_is, props_positive, M\n",
    "\n",
    "        N = x.shape[0]\n",
    "        client_size = int(np.floor(N/M))\n",
    "\n",
    "        class_balance = np.mean(y == 0)\n",
    "\n",
    "        pos_inds = np.where(y > 0)\n",
    "        zero_inds = np.where(y == 0)\n",
    "        \n",
    "        assert (len(pos_inds[0]) + len(zero_inds[0])) == len(y), \"Some indeces missed.\"\n",
    "        \n",
    "        print(f'x shape {x.shape}')\n",
    "\n",
    "        y_pos = y[pos_inds]\n",
    "        y_neg = y[zero_inds]\n",
    "\n",
    "        x_pos = x[pos_inds]\n",
    "        x_neg = x[zero_inds]\n",
    "\n",
    "        client_data = []\n",
    "\n",
    "        # Recombine remaining data and shuffle.\n",
    "        x = np.concatenate([x_pos, x_neg])\n",
    "        y = np.concatenate([y_pos, y_neg])\n",
    "        \n",
    "        # As in Bui et al, order according to x1 value.\n",
    "        inds = np.argsort(x[:, 0])\n",
    "\n",
    "        x = x[inds]\n",
    "        y = y[inds]\n",
    "\n",
    "        # Distribute among clients.\n",
    "        for i in range(M):\n",
    "            client_x = x[:client_size]\n",
    "            client_y = y[:client_size]\n",
    "\n",
    "            x = x[client_size:]\n",
    "            y = y[client_size:]\n",
    "\n",
    "            client_data.append({'x': client_x, 'y': client_y})\n",
    "\n",
    "        N_is = [data['x'].shape[0] for data in client_data]\n",
    "        props_positive = [np.mean(data['y'] > 0) for data in client_data]\n",
    "\n",
    "        np.random.set_state(random_state)\n",
    "\n",
    "        return client_data, N_is, props_positive, M\n",
    "    \n",
    "def plot_data(x, y, ax=None):\n",
    "    x1_min, x1_max = -3., 3.\n",
    "    x2_min, x2_max = -3., 3.\n",
    "    \n",
    "    x1x1, x2x2 = np.meshgrid(np.linspace(x1_min, x1_max, 100), \n",
    "                             np.linspace(x2_min, x2_max, 100))\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(8, 6), dpi=200)\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    ax.plot(x[y == 0, 0], x[y == 0, 1], \"o\", color=\"C1\", label=\"Class 1\", alpha=.5, zorder=1)\n",
    "    ax.plot(x[y == 1, 0], x[y == 1, 1], \"o\", color=\"C0\", label=\"Class 2\", alpha=.5, zorder=1)\n",
    "    \n",
    "    ax.set_xlabel(\"x1\")\n",
    "    ax.set_ylabel(\"x2\")\n",
    "    ax.set_xlim(x1x1.min(), x1x1.max())\n",
    "    ax.set_ylim(x2x2.min(), x2x2.max())\n",
    "    ax.legend(loc=\"upper left\", scatterpoints=1, numpoints=1)\n",
    "    \n",
    "    return x1x1, x2x2\n",
    "\n",
    "def acc_and_ll(pred_probs, x, y):\n",
    "    \n",
    "    acc = np.mean((pred_probs > 0.5) == y)\n",
    "    \n",
    "    probs = torch.clip(torch.tensor(pred_probs), 0., 1.)\n",
    "    loglik = torch.distributions.Bernoulli(probs=probs).log_prob(torch.tensor(y))\n",
    "    loglik = loglik.mean().numpy()\n",
    "    \n",
    "    return acc, loglik\n",
    "\n",
    "def plot_predictive_distribution(x, y, z, model=None, q=None, ax=None, x_old=None, y_old=None, z_old=None):\n",
    "    x1x1, x2x2 = plot_data(x, y, ax)\n",
    "    ax.scatter(z[:, 0], z[:, 1], color=\"r\", marker=\"o\", zorder=3)\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    if model is not None and q is not None:\n",
    "        x_predict = np.concatenate((x1x1.ravel().reshape(-1, 1), \n",
    "                                    x2x2.ravel().reshape(-1, 1)), 1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_predict = model(torch.tensor(x_predict), q=q, diag=True)\n",
    "            y_predict = y_predict.mean.numpy().reshape(x1x1.shape)\n",
    "            \n",
    "        cs2 = ax.contour(x1x1, x2x2, y_predict, colors=[\"k\"], levels=[0.2, 0.5, 0.8], zorder=2)\n",
    "        ax.clabel(cs2, fmt=\"%2.1f\", colors=\"k\", fontsize=14)\n",
    "    \n",
    "    if x_old is not None and y_old is not None:\n",
    "        ax.plot(x_old[y_old == 0, 0], x_old[y_old == 0, 1], \"o\", color=\"C1\", label=\"Class 1\", alpha=.25)\n",
    "        ax.plot(x_old[y_old == 1, 0], x_old[y_old == 1, 1], \"o\", color=\"C0\", label=\"Class 2\", alpha=.25)\n",
    "        \n",
    "        if z_old is not None:\n",
    "            ax.scatter(z_old[:, 0], z_old[:, 1], color=\"r\", marker=\"o\", alpha=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-reflection",
   "metadata": {},
   "source": [
    "Change these to the directory of banana.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"banana\"\n",
    "data_base_dir = \"/Users/matt/projects/pvi/datasets\"\n",
    "train_proportion = 0.08\n",
    "\n",
    "training_set, test_set, D = load_data(\n",
    "    name, train_proportion, data_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 3\n",
    "\n",
    "clients_data, nis, prop_positive, M = generate_clients_data(\n",
    "    training_set[\"x\"], \n",
    "    training_set[\"y\"],\n",
    "    M=M,\n",
    "    dataset_seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-touch",
   "metadata": {},
   "source": [
    "### Set up clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inducing = 10\n",
    "\n",
    "# Shared across all clients.\n",
    "model_config = {\n",
    "    \"D\": D,\n",
    "    \"num_inducing\": num_inducing,\n",
    "    \"kernel_class\": lambda **kwargs: RBFKernel(**kwargs),\n",
    "    \"kernel_params\": {\n",
    "        \"ard_num_dims\": D, \n",
    "        \"train_hypers\": True\n",
    "    },\n",
    "    \"num_predictive_samples\": 100\n",
    "}\n",
    "\n",
    "client_config = {\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"optimiser_params\": {\"lr\": 1e-2},\n",
    "    \"epochs\": 2000,\n",
    "    \"batch_size\": len(clients_data[0][\"x\"]),\n",
    "    \"num_elbo_samples\": 10,\n",
    "    \"num_elbo_hyper_samples\": 2,\n",
    "    \"num_predictive_samples\": 100,\n",
    "    \"train_model\": False,\n",
    "    \"damping_factor\": .25,\n",
    "    \"valid_factors\": False,\n",
    "    \"early_stopping\": EarlyStopping(50)\n",
    "}\n",
    "\n",
    "server_config = {\n",
    "    \"max_iterations\": 50,\n",
    "    \"train_model\": False,\n",
    "    \"hyper_optimiser\": \"SGD\",\n",
    "    \"hyper_optimiser_params\": {\"lr\": 1},\n",
    "    \"hyper_updates\": 10,\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"optimiser_params\": {\"lr\": 1e-2},\n",
    "    \"epochs\": 2000,\n",
    "    \"early_stopping\": EarlyStopping(25, delta=1e-2),\n",
    "    \"num_elbo_samples\": 10,\n",
    "}\n",
    "\n",
    "init_nat_params = {\n",
    "    \"np1\": torch.zeros(model_config[\"num_inducing\"]),\n",
    "    \"np2\": torch.zeros(model_config[\"num_inducing\"]).diag_embed(),\n",
    "}\n",
    "\n",
    "prior_nat_params = {\n",
    "    \"np1\": torch.zeros(model_config[\"num_inducing\"]),\n",
    "    \"np2\": -0.5 * torch.ones(model_config[\"num_inducing\"]).diag_embed(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct clients.\n",
    "clients = []\n",
    "z_is = []\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "for i in range(M):\n",
    "    model_i = SparseGaussianProcessClassification(config=model_config)\n",
    "    data_i = clients_data[i]\n",
    "    \n",
    "    # Randomly initialise private inducing points.\n",
    "    perm = torch.randperm(len(data_i[\"x\"]))\n",
    "    idx = perm[:model_config[\"num_inducing\"]]\n",
    "    z_i = torch.tensor(data_i[\"x\"][idx])\n",
    "    z_is.append(z_i)\n",
    "    \n",
    "    # Convert to torch.tensor.\n",
    "    for k, v in data_i.items():\n",
    "        data_i[k] = torch.tensor(v)\n",
    "    \n",
    "    t = MultivariateGaussianFactorWithZ(\n",
    "        nat_params=init_nat_params,\n",
    "        inducing_locations=z_i,\n",
    "        train_inducing=True,\n",
    "    )\n",
    "    \n",
    "    clients.append(FederatedSGPClient(data=data_i, model=model_i, t=t, config=client_config))\n",
    "\n",
    "# Construct global model and server.\n",
    "model = SparseGaussianProcessClassification(config=model_config)\n",
    "\n",
    "# Union of z_is.\n",
    "z = torch.cat(z_is)\n",
    "kzz = model.kernel(z, z)\n",
    "q = MultivariateGaussianDistributionWithZ(\n",
    "    std_params = {\n",
    "        \"loc\": torch.zeros(z.shape[0]),\n",
    "        \"covariance_matrix\": kzz,\n",
    "    }, \n",
    "    inducing_locations=z,\n",
    "    train_inducing=True\n",
    ")\n",
    "\n",
    "# Randomly initialise global inducing points.\n",
    "perm = torch.randperm(len(training_set[\"x\"]))\n",
    "idx = perm[:10]\n",
    "z = torch.tensor(training_set[\"x\"][idx])\n",
    "kzz = model.kernel(z, z)\n",
    "q = MultivariateGaussianDistributionWithZ(\n",
    "    std_params = {\n",
    "        \"loc\": torch.zeros(z.shape[0]),\n",
    "        \"covariance_matrix\": kzz,\n",
    "    }, \n",
    "    inducing_locations=z,\n",
    "    train_inducing=True\n",
    ")\n",
    "\n",
    "server = SequentialSGPServer(\n",
    "    model=model, \n",
    "    p=q, \n",
    "    clients=clients,\n",
    "    config=server_config,\n",
    "    maintain_inducing=True,    # Set to False to use union of inducing points.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-waste",
   "metadata": {},
   "source": [
    "### Run streaming SGP with private inducing points!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "while not server.should_stop():\n",
    "    server.tick()\n",
    "\n",
    "    # Obtain predictions.\n",
    "    pp = server.model_predict(torch.tensor(test_set[\"x\"]))\n",
    "\n",
    "    preds = pp.mean.detach().numpy()\n",
    "    test_acc, test_mll = acc_and_ll(preds, test_set[\"x\"], test_set[\"y\"])\n",
    "\n",
    "    print(test_acc)\n",
    "    print(test_mll)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 6), dpi=100, constrained_layout=True)\n",
    "    gs = fig.add_gridspec(2, 3)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "    for i, (client, ax) in enumerate(zip(clients, [ax1, ax2, ax3])):\n",
    "        plot_predictive_distribution(\n",
    "            client.data[\"x\"], client.data[\"y\"], z=client.t.inducing_locations, ax=ax)\n",
    "        ax.set_title(\"Client {}\".format(i))\n",
    "\n",
    "    plot_predictive_distribution(\n",
    "        training_set[\"x\"], training_set[\"y\"], z=server.q.inducing_locations,\n",
    "        model=server.model, q=server.q, ax=ax4)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
