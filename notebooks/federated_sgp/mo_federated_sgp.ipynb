{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alpha-trading",
   "metadata": {},
   "source": [
    "# Multi-output federated SGPs\n",
    "\n",
    "Performance on the development index classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"/Users/matt/projects/pvi\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.auto as tqdm\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pvi.models import MOSparseGaussianProcessClassification\n",
    "from pvi.distributions import MultivariateGaussianDistributionWithZ, MultivariateGaussianFactorWithZ\n",
    "from pvi.clients.federated_sgp import FederatedSGPClient\n",
    "from pvi.servers import GlobalVIServer\n",
    "from pvi.servers.federated_sgp import SequentialSGPServer, SynchronousSGPServer\n",
    "from pvi.models.sgp.kernels import RBFKernel\n",
    "from pvi.utils.training_utils import EarlyStopping\n",
    "from data.split_data import homogenous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-bhutan",
   "metadata": {},
   "source": [
    "# Load data and set up helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Normalise data.\n",
    "x = (x - x.mean(axis=0)) / x.std(axis=0)\n",
    "\n",
    "ntrain = 100\n",
    "perm = np.random.permutation(len(y))\n",
    "\n",
    "train_data = {\n",
    "    \"x\": torch.tensor(x[perm[:ntrain]]),\n",
    "    \"y\": torch.tensor(y[perm[:ntrain]]),\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    \"x\": torch.tensor(x[perm[ntrain:]]),\n",
    "    \"y\": torch.tensor(y[perm[ntrain:]]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics(client, data):\n",
    "    x, y = data[\"x\"], data[\"y\"]\n",
    "    \n",
    "    pp = client.model_predict(x)\n",
    "    preds = pp.component_distribution.probs.mean(1)\n",
    "    \n",
    "    mll = pp.log_prob(y).mean()\n",
    "    acc = sum(torch.argmax(preds, dim=-1) == y) / len(y)\n",
    "    \n",
    "    metrics = {\n",
    "        \"acc\": acc.item(),\n",
    "        \"mll\": mll.item(),\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "class Client():\n",
    "    def __init__(self, data):\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-institution",
   "metadata": {},
   "source": [
    "# Model, client and server configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inducing = 10\n",
    "D = x.shape[1]\n",
    "P = 3\n",
    "\n",
    "# Shared across all clients.\n",
    "model_config = {\n",
    "    \"D\": D,\n",
    "    \"P\": P,\n",
    "    \"share_kernel\": False,\n",
    "    \"num_inducing\": num_inducing,\n",
    "    \"kernel_class\": lambda **kwargs: RBFKernel(**kwargs),\n",
    "    \"kernel_params\": {\n",
    "        \"ard_num_dims\": D, \n",
    "        \"train_hypers\": False,    # Don't train kernel hyperparameters for now.\n",
    "    },\n",
    "    \"num_predictive_samples\": 100\n",
    "}\n",
    "\n",
    "server_config = {\n",
    "    \"max_iterations\": 1,\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"optimiser_params\": {\"lr\": 1e-3},\n",
    "    \"epochs\": 2000,\n",
    "    \"num_elbo_samples\": 100,\n",
    "    \"print_epochs\": 10,\n",
    "    \"performance_metrics\": performance_metrics,\n",
    "    \"early_stopping\": EarlyStopping(25),\n",
    "    \"train_model\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct client.\n",
    "client = Client(train_data)\n",
    "\n",
    "# Construct server.\n",
    "model = MOSparseGaussianProcessClassification(config=model_config)\n",
    "\n",
    "# Randomly initialise global inducing points.\n",
    "perm = torch.randperm(len(train_data[\"x\"]))\n",
    "z = torch.tensor(train_data[\"x\"][perm[:num_inducing]])\n",
    "kzz = model.kernel(z, z)\n",
    "\n",
    "p = MultivariateGaussianDistributionWithZ(\n",
    "    std_params = {\n",
    "        \"loc\": torch.zeros(z.shape[0]).unsqueeze(0).repeat(P, 1),\n",
    "        \"covariance_matrix\": kzz,\n",
    "    },  \n",
    "    inducing_locations=z,\n",
    "    train_inducing=True,\n",
    "    is_trainable=False\n",
    ")\n",
    "\n",
    "server = GlobalVIServer(model=model, p=p, clients=[client], config=server_config, val_data=test_data)\n",
    "\n",
    "# Obtain prior predictions.\n",
    "train_metrics = performance_metrics(server, train_data)\n",
    "test_metrics = performance_metrics(server, test_data)\n",
    "print(\"Test mll: {:.3f}. Test acc: {:.3f}.\".format(test_metrics[\"mll\"], test_metrics[\"acc\"]))\n",
    "print(\"Train mll: {:.3f}. Train acc: {:.3f}.\\n\".format(train_metrics[\"mll\"], train_metrics[\"acc\"]))\n",
    "\n",
    "# Run PVI!\n",
    "while not server.should_stop():\n",
    "    server.tick()\n",
    "\n",
    "    # Obtain predictions.\n",
    "    train_metrics = performance_metrics(server, train_data)\n",
    "    test_metrics = performance_metrics(server, test_data)\n",
    "    print(\"Test mll: {:.3f}. Test acc: {:.3f}.\".format(test_metrics[\"mll\"], test_metrics[\"acc\"]))\n",
    "    print(\"Train mll: {:.3f}. Train acc: {:.3f}.\\n\".format(train_metrics[\"mll\"], train_metrics[\"acc\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-station",
   "metadata": {},
   "source": [
    "# Now try PVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inducing = 5\n",
    "\n",
    "client_config = {\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"optimiser_params\": {\"lr\": 1e-3},\n",
    "    \"epochs\": 2000,\n",
    "    \"batch_size\": 50,\n",
    "    \"num_elbo_samples\": 10,\n",
    "    \"num_elbo_hyper_samples\": 2,\n",
    "    \"valid_factors\": True,\n",
    "    \"early_stopping\": EarlyStopping(25),\n",
    "    \"damping_factor\": 1.\n",
    "}\n",
    "\n",
    "# Shared across all clients.\n",
    "model_config = {\n",
    "    \"D\": D,\n",
    "    \"P\": P,\n",
    "    \"share_kernel\": False,\n",
    "    \"num_inducing\": num_inducing,\n",
    "    \"kernel_class\": lambda **kwargs: RBFKernel(**kwargs),\n",
    "    \"kernel_params\": {\n",
    "        \"ard_num_dims\": D, \n",
    "        \"train_hypers\": False\n",
    "    },\n",
    "    \"num_predictive_samples\": 100\n",
    "}\n",
    "\n",
    "server_config[\"max_iterations\"] = 10\n",
    "\n",
    "init_nat_params = {\n",
    "    \"np1\": torch.zeros(model_config[\"num_inducing\"]),\n",
    "    \"np2\": torch.zeros(model_config[\"num_inducing\"]).diag_embed(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 2\n",
    "clients_data = homogenous(train_data[\"x\"], train_data[\"y\"], m=M, dataset_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct clients.\n",
    "clients = []\n",
    "z_is = []\n",
    "\n",
    "for i in range(M):\n",
    "    model_i = MOSparseGaussianProcessClassification(config=model_config)\n",
    "    data_i = clients_data[i]\n",
    "    \n",
    "    # Randomly initialise private inducing points.\n",
    "    perm = torch.randperm(len(data_i[\"x\"]))\n",
    "    z_i = torch.tensor(data_i[\"x\"][perm[:num_inducing]])\n",
    "    z_is.append(z_i)\n",
    "    \n",
    "    # Convert to torch.tensor.\n",
    "    for k, v in data_i.items():\n",
    "        data_i[k] = torch.tensor(v)\n",
    "    \n",
    "    t = MultivariateGaussianFactorWithZ(\n",
    "        nat_params=init_nat_params,\n",
    "        inducing_locations=z_i,\n",
    "        train_inducing=True,\n",
    "    )\n",
    "    \n",
    "    clients.append(FederatedSGPClient(data=data_i, model=model_i, t=t, config=client_config))\n",
    "\n",
    "# Construct global model and server.\n",
    "model = MOSparseGaussianProcessClassification(config=model_config)\n",
    "p = None\n",
    "\n",
    "server = SequentialSGPServer(\n",
    "    model=model, \n",
    "    p=p, \n",
    "    clients=clients, \n",
    "    config=server_config, \n",
    "    maintain_inducing=False\n",
    ")\n",
    "\n",
    "# Run PVI!\n",
    "while not server.should_stop():\n",
    "    server.tick()\n",
    "\n",
    "    # Obtain predictions.\n",
    "    train_metrics = performance_metrics(server, train_data)\n",
    "    test_metrics = performance_metrics(server, test_data)\n",
    "    print(\"Test mll: {:.3f}. Test acc: {:.3f}.\".format(test_metrics[\"mll\"], test_metrics[\"acc\"]))\n",
    "    print(\"Train mll: {:.3f}. Train acc: {:.3f}.\\n\".format(train_metrics[\"mll\"], train_metrics[\"acc\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
